{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cd23780",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup \n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f8a704fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 'NoneType' object has no attribute 'find'\n",
      "['\\n\\nPython Tutor\\n\\n\\n', '\\n\\nPython Django Developer\\n\\n\\n'] ['\\n\\nMero Coding Class\\n\\n', '\\n\\nBisava Tech\\n\\n'] ['Min Bhawan, New Baneshwor', 'Kathmandu'] ['merojob.com', 'merojob.com']\n",
      "1\n",
      "2\n",
      "3\n",
      "['\\n\\nPython Tutor\\n\\n\\n', '\\n\\nPython Django Developer\\n\\n\\n', 'Sr. full Stack Developer(Python+React)', 'Sr. Python Django Developer'] ['\\n\\nMero Coding Class\\n\\n', '\\n\\nBisava Tech\\n\\n', 'Khalti Digital Wallet', 'Khalti Digital Wallet'] ['Min Bhawan, New Baneshwor', 'Kathmandu', 'Pulchowk Lalitpur - Nepal', 'Pulchowk Lalitpur - Nepal'] ['merojob.com', 'merojob.com', 'merojob.com', 'merojob.com']\n",
      "['\\n\\nPython Tutor\\n\\n\\n', '\\n\\nPython Django Developer\\n\\n\\n', 'Sr. full Stack Developer(Python+React)', 'Sr. Python Django Developer', '\\nPython Developer\\n']\n"
     ]
    }
   ],
   "source": [
    "position_list=[]\n",
    "address_list=[]\n",
    "company_list=[]\n",
    "website_list=[]\n",
    "\n",
    "url_list=['https://merojob.com/search/?q=python&start_date=&end_date=',\n",
    "          'https://www.slicejob.com/jobs/search/?job_category=&job_tittle=python&submit=Search',\n",
    "          'https://sabaikojobs.com/search',\n",
    "         ]\n",
    "\n",
    "for i in range(len(url_list)):\n",
    "    if 'merojob.com' in url_list[i]:\n",
    "        url=url_list[i]\n",
    "        try:\n",
    "            source=requests.get(url)\n",
    "            source.raise_for_status()\n",
    "            soup=BeautifulSoup(source.text,'html.parser')\n",
    "            try:\n",
    "                listOfpage=soup.find('ul',class_=\"pagination pagination-sm\")\n",
    "                allpage=listOfpage.find_all('a',class_='page-link')\n",
    "                for i in range(len(allpage[:-1])):\n",
    "                    url='https://merojob.com/search/?q=python&start_date=&end_date='+str(i)\n",
    "                    box=soup.find('div',id=\"search_job\")\n",
    "                    position=box.find_all('h1', class_=\"text-primary\")\n",
    "                    for i in position:\n",
    "                        website_list.append(\"merojob.com\")\n",
    "                        jobPost=i.text\n",
    "                        position_list.append(jobPost)\n",
    "\n",
    "                    company=box.find_all('h3', class_=\"h6\")\n",
    "                    for i in company:\n",
    "                        companyName=i.text\n",
    "                        company_list.append(companyName)\n",
    "\n",
    "                    address=box.find_all('span',itemprop=\"addressLocality\")\n",
    "                    for i in address:\n",
    "                        addressOfCompay=i.text\n",
    "                        address_list.append(addressOfCompay)\n",
    "\n",
    "                    print(position_list,company_list,address_list,website_list)\n",
    "\n",
    "            except AttributeError:\n",
    "                print(\"Error: 'NoneType' object has no attribute 'find'\")\n",
    "        \n",
    "                box=soup.find('div',id=\"search_job\")\n",
    "\n",
    "                position=box.find_all('h1', class_=\"text-primary\")\n",
    "                for i in position:\n",
    "                    website_list.append(\"merojob.com\")\n",
    "                    jobPost=i.text\n",
    "                    position_list.append(jobPost)\n",
    "\n",
    "                company=box.find_all('h3', class_=\"h6\")\n",
    "                for i in company:\n",
    "                    companyName=i.text\n",
    "                    company_list.append(companyName)\n",
    "\n",
    "                address=box.find_all('span',itemprop=\"addressLocality\")\n",
    "                for i in address:\n",
    "                    addressOfCompay=i.text\n",
    "                    address_list.append(addressOfCompay)\n",
    "                print(position_list,company_list,address_list,website_list) \n",
    "\n",
    "        except Exception as e:\n",
    "                print(e)\n",
    "for i in range(len(url_list)):\n",
    "    if 'slicejob.com' in url_list[i]:\n",
    "        url=url_list[i]\n",
    "        try:\n",
    "            source=requests.get(url)\n",
    "            source.raise_for_status()\n",
    "            soup=BeautifulSoup(source.text,'html.parser')\n",
    "            box=soup.find('div',id=\"job_list\")\n",
    "            try:\n",
    "                listOfpage=soup.find('ul',class_=\"pagination\")\n",
    "                allpage=listOfpage.find_all('a')\n",
    "\n",
    "                for i in range(1,len(allpage)-1):\n",
    "                    print(i)\n",
    "                    url='https://www.slicejob.com/jobs/search/?job_category=&job_tittle=python&submit=Search&page='+str(i)\n",
    "\n",
    "                    source=requests.get(url)\n",
    "                    source.raise_for_status()\n",
    "                    soup=BeautifulSoup(source.text,'html.parser')\n",
    "                    box=soup.find('div',id=\"job_list\")\n",
    "\n",
    "                    position=box.find_all('li', class_=\"job_tittle\")\n",
    "                    for i in position:\n",
    "                        website_list.append(\"merojob.com\")\n",
    "                        jobPost=i.text\n",
    "                        position_list.append(jobPost)\n",
    "\n",
    "                    company=box.find_all('img')\n",
    "                    for i in range(len(company)):\n",
    "                        companyName=company[i].get(\"alt\")\n",
    "                        company_list.append(companyName)\n",
    "\n",
    "                    address=box.find_all('li',class_='job_company')\n",
    "                    for i in address:\n",
    "                        addressOfCompay=i.text\n",
    "                        address_list.append(addressOfCompay)\n",
    "\n",
    "                print(position_list,company_list,address_list,website_list)\n",
    "\n",
    "            except AttributeError:\n",
    "                print(\"Error: 'NoneType' object has no attribute 'find'\")\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            \n",
    "for i in range(len(url_list)):\n",
    "    if 'sabaikojobs.com' in url_list[i]:\n",
    "        url=url_list[i]  \n",
    "        try:\n",
    "            source=requests.get(url)\n",
    "            source.raise_for_status()\n",
    "            soup=BeautifulSoup(source.text,'html.parser')\n",
    "            box=soup.find('div',id=\"srch_output\")\n",
    "\n",
    "            position=box.find_all('div', class_=\"job_block_ttl\")\n",
    "            for i in position:\n",
    "                jobPost=i.text\n",
    "                if 'python' in jobPost.lower():\n",
    "                    website_list.append(\"sabaikojobs.com\")\n",
    "                    position_list.append(jobPost)\n",
    "            print(position_list)\n",
    "\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "30c21acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/search/?q=time&start_date=&end_date=&page=1\n"
     ]
    }
   ],
   "source": [
    "# nextpage=soup.find('a',class_=\"page-link\").get(\"href\")\n",
    "# print(nextpage)\n",
    "# url='https://merojob.com/search/?q=python&start_date=&end_date=bibhuti'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "114e25ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"job_block_ttl\">\n",
      "<a href=\"https://sabaikojobs.com/jobs/python-developer/1170\">Python Developer</a>\n",
      "</div>\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "position_list=[]\n",
    "address_list=[]\n",
    "company_list=[]\n",
    "website_list=[]\n",
    "\n",
    "url='https://sabaikojobs.com/search'\n",
    "\n",
    "try:\n",
    "    source=requests.get(url)\n",
    "    source.raise_for_status()\n",
    "    soup=BeautifulSoup(source.text,'html.parser')\n",
    "    box=soup.find('div',id=\"srch_output\")\n",
    "    \n",
    "    position=box.find_all('div', class_=\"job_block_ttl\")\n",
    "    \n",
    "    for i in position:\n",
    "        jobPost=i.text\n",
    "        if 'python' in jobPost.lower():\n",
    "            print(i)\n",
    "            website_list.append(\"sabaikojobs.com\")\n",
    "            position_list.append(jobPost)\n",
    "            \n",
    "            company_list=box.find('div', class_=\"job_block\")\n",
    "            company=i.find('div', class_=\"job_block_company_name\")\n",
    "            \n",
    "#             company=i.next_sibling\n",
    "#             companyName=company.text\n",
    "#             company_list.append(companyName)\n",
    "    \n",
    "    print(company)\n",
    "    \n",
    "except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fb7d2319",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
